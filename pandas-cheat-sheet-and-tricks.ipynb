{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amsamms/pandas-useful-tricks?scriptVersionId=115672181\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-21T05:35:53.090722Z","iopub.execute_input":"2022-05-21T05:35:53.091566Z","iopub.status.idle":"2022-05-21T05:35:53.121021Z","shell.execute_reply.started":"2022-05-21T05:35:53.091461Z","shell.execute_reply":"2022-05-21T05:35:53.120101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make mixed test dataframe\ndf=pd.util.testing.makeMixedDataFrame()  # after (.make) you can hit tab to see other variation of creating a datafram\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-19T14:45:24.711292Z","iopub.execute_input":"2022-05-19T14:45:24.712051Z","iopub.status.idle":"2022-05-19T14:45:24.725735Z","shell.execute_reply.started":"2022-05-19T14:45:24.712014Z","shell.execute_reply":"2022-05-19T14:45:24.725254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#groupby\n# df.grooupby ( ['column_name1', 'column_name2'], as_index=False)['column_name3','column_name4'].agg(['function1','function2'])\ndf.groupby(['A'], as_index=False)['B'].agg(['mean','min'])\n\n\n# single groupby\ndf.groupby('unit').sum() # for summing all data based on groubed by column, sum can be replaced by first or any other function","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:08:35.389394Z","iopub.execute_input":"2022-05-19T15:08:35.389667Z","iopub.status.idle":"2022-05-19T15:08:35.403756Z","shell.execute_reply.started":"2022-05-19T15:08:35.389635Z","shell.execute_reply":"2022-05-19T15:08:35.403145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calling only numeric values in a dataframe\ndf[df.describe().columns] # 1st method\n\ndf[df.dtypes[df.dtypes!='object'].index] # second method with the same results\n\ndf.select_dtype(include='number').columns # third method, also execlude can be used, np.number also can be used instead of numbers\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:11:38.344068Z","iopub.execute_input":"2022-05-19T15:11:38.344701Z","iopub.status.idle":"2022-05-19T15:11:38.366474Z","shell.execute_reply.started":"2022-05-19T15:11:38.344663Z","shell.execute_reply":"2022-05-19T15:11:38.365524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calling only non numeric values in a dataframe \ndf[df.dtypes[df.dtypes=='object'].index] # 1st method\n\ndf[df.drop(df.describe().columns,axis=1).columns] # second method with the same results\n\ndf.select_dtypes(exclude='number').columns # third method , also include can be used","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:11:03.75822Z","iopub.execute_input":"2022-05-19T15:11:03.759055Z","iopub.status.idle":"2022-05-19T15:11:03.775304Z","shell.execute_reply.started":"2022-05-19T15:11:03.759016Z","shell.execute_reply":"2022-05-19T15:11:03.774476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# differene between .any() & .all() \ndf2 = pd.DataFrame()\ndf2['x'] = [1,2,3]\ndf2['y'] = [3,4,5]\nprint(df2)\nprint(df2<2.5)\nprint((df2< 2.5).all(axis = 1))\nprint((df2 < 2.5).any(axis = 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T14:48:11.43189Z","iopub.execute_input":"2022-05-19T14:48:11.43218Z","iopub.status.idle":"2022-05-19T14:48:11.447405Z","shell.execute_reply.started":"2022-05-19T14:48:11.432148Z","shell.execute_reply":"2022-05-19T14:48:11.446468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using in operator with dataframe\n\ndf['A'].isin([1,2,4,6]) # df[column].isin(list-like)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:11:38.640154Z","iopub.execute_input":"2022-05-19T15:11:38.640888Z","iopub.status.idle":"2022-05-19T15:11:38.647762Z","shell.execute_reply.started":"2022-05-19T15:11:38.64084Z","shell.execute_reply":"2022-05-19T15:11:38.647153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keep only columns where 65% or more valid data is available, drop the rest \ndf.dropna(axis='columns', how='any', thresh=df.shape[0]*0.65, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:12:09.588405Z","iopub.execute_input":"2022-05-19T15:12:09.589082Z","iopub.status.idle":"2022-05-19T15:12:09.595787Z","shell.execute_reply.started":"2022-05-19T15:12:09.589042Z","shell.execute_reply":"2022-05-19T15:12:09.594706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check data type of specefic column for each cell in pandas\ndf=pd.util.testing.makeMixedDataFrame()\ndf['A'].apply(type)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:12:14.701733Z","iopub.execute_input":"2022-05-19T15:12:14.702127Z","iopub.status.idle":"2022-05-19T15:12:14.711219Z","shell.execute_reply.started":"2022-05-19T15:12:14.702098Z","shell.execute_reply":"2022-05-19T15:12:14.710437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to know each data type of specefic column\ndf['B'].apply(type).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:12:18.096313Z","iopub.execute_input":"2022-05-19T15:12:18.097119Z","iopub.status.idle":"2022-05-19T15:12:18.104334Z","shell.execute_reply.started":"2022-05-19T15:12:18.09708Z","shell.execute_reply":"2022-05-19T15:12:18.103772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to search for data type in specefic column that is not a certain type\ndf['A'].apply(type)!= str","metadata":{"execution":{"iopub.status.busy":"2022-05-19T15:12:22.038421Z","iopub.execute_input":"2022-05-19T15:12:22.03885Z","iopub.status.idle":"2022-05-19T15:12:22.04632Z","shell.execute_reply.started":"2022-05-19T15:12:22.038817Z","shell.execute_reply":"2022-05-19T15:12:22.04539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# interpolation can be for dataframe or series :\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n# https://pandas.pydata.org/docs/reference/api/pandas.Series.interpolate.html\ndf=pd.util.testing.makeMissingDataframe()\ndf['B']=df['B'].interpolate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply function to multiple columns:\ndf=pd.util.testing.makeDataFrame()\n# df[new_column]=df.apply(lambda x : function(x[col1],x[col2],..), axis=1)\ndef get(x,y,z):\n    return (x+y-z)\n\ndf['H']=df.apply(lambda x : get(x['A'],x['B'],x['C']), axis=1) # Don't forget to use X not df inside the function\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-21T05:43:47.702427Z","iopub.execute_input":"2022-05-21T05:43:47.702795Z","iopub.status.idle":"2022-05-21T05:43:47.726794Z","shell.execute_reply.started":"2022-05-21T05:43:47.702761Z","shell.execute_reply":"2022-05-21T05:43:47.726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://towardsdatascience.com/interesting-ways-to-select-pandas-dataframe-columns-b29b82bbfb33#:~:text=Selecting%20columns%20based%20on%20their,Returns%20a%20pandas%20series.&text=Passing%20a%20list%20in%20the,columns%20at%20the%20same%20time.# \n#columns selection\n\n#Selecting a subset of columns found in a list\ndf[df.columns[df.columns.isin(['alcohol','hue','NON-EXISTANT COLUMN'])]]\n\n#Selecting a subset of columns based on difference of columns\ndf[df.columns.difference([‘alcohol’,’hue’])]\n\n#Selecting a subset of columns that is not in a list\ndf[df.columns[~df.columns.isin(['alcohol','hue'])]]\n\n#Selecting columns based on their data type\ndf.loc[:,(df.dtypes=='float64').values]\n\n#Selecting columns based on their column name containing a substring\ndf[df.columns.str.contains('combined_feed_x_factor|Dt_|combined_feed_sm3/hr|combined_feed_s.g._@)\n                                   \n#Selecting columns based on their column name containing a string wildcard\ndf.loc[:,[True if re.search('flava+',column) else False for column in df.columns]]\n                            \n#Selecting columns based on how their column name starts\ndf.loc[:,df.columns.str.startswith('al')]\n                                   \n#Selecting columns based on how their column name ends\ndf.loc[:,df.columns.str.endswith('oids')]\n                                   \n#Selecting columns if all rows meet a condition\ndf.loc[:,[(df[col] > 14).all() for col in df.columns]]\n                           \n#Selecting columns if any row of a column meets a condition\ndf.loc[:,[(df[col] > 14).any() for col in df.columns]]\n                                   \n#Selecting columns if the average of rows in a column meet a condition\ndf.loc[:,[(df[col].mean() > 7) for col in df.columns]]\n                           \n                           \n    \n                                   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display Nan values in a dataframe\n\ndf.loc[df.isna().any(axis=1),df.isna().any(axis=0)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# search for specefic  row and column that have a specefic value in the entire data frame :\ndf.loc[(df.values==86.80).any(axis=1),(df.values==86.80).any(axis=0)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Column orders rearrangements\ndf = df[['date'] + columns[1:]] #now the date column is the first column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set pandas display options\npd.set_option('display.max_columns',300) # for number of displayed columns\npd.set_option('max_colwidth',900) # for width of each column, there is a lot of options in set options\n\n\n# set pandas display float format\npd.options.display.float_format = '{:,.8f}'.format","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choosing tenth or hundredth of float column\ndf['tenth']=df['number'].astype(str).str[1], # the new column is string\ndf['hundredth']=df['number'].astype(str).str[2], # the new column is sstring","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping\n\ndf.drop(['A','B','C'], axis=1, inplac=True) # dropping columns inplace\n\ndf.drop(df[df['nan_per_row']>28].index,inplace=True) # dropping some raws with specefic conditions\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing duplicated column\n#https://sparkbyexamples.com/pandas/pandas-remove-duplicate-columns-from-dataframe/\n\ndf2 = df.T.drop_duplicates().T # this method remove duplicated column even if the column name is different\n\ndf2 = df.loc[:,~df.columns.duplicated()]# this method removes duplicated column sharing the same name\n\n# join columns sharing the same name\n# https://stackoverflow.com/questions/49431864/how-to-join-columns-sharing-the-same-name-within-a-dataframe\ndf=df.groupby(df.columns, axis=1).first() # first returns first non nan values\n\n# to remove duplicated columns names ( even if they are not the same in values):\n#https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\ndf = df.loc[:,~df.columns.duplicated()].copy()\n\n\n# removing dupliocated index\n\ndf = df[~df.index.duplicated(keep=\"first\")]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imputation using pandas\n\n# impute numeric columns with mean or median\ndf[num_cols].fillna(df[num_cols].mean()) # inplace to be true\ndf[num_cols].fillna(df[num_cols].median()) # inplace to be true\n\n# impute categorical columns\ndf[cat_cols].fillna(df[cat_cols].mode().iloc[0]) # inplace to be true","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting dataframe to numeric values, all other non-numbers will converted to Nan\nfor column in df.columns:\n    df[column]=pd.to_numeric(df[column],errors='coerce')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concat & Merge\n# Concat is putting dataframes beside eachother regardless of index or anything\n# Merging is putting dataframes beside eachother having common index, or column as a reference\npd.concat([df1, df2])) # concat horizontally ( df2 below df1)\npd.concat([df1,df2],axis=1) # concat vertically (df2 on the rightside of df1)\n#Concated dataframes needs to have single indexing\n#if concate herozontally ( axis=0) make sure columns of dataframe is not duplicated\n#if concate vertically ( axis=1) make sure index of dataframe is not duplicated\n\n\n\ndf1.merge(df2, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False) \n# merging on index the last two arguments should be true\n# if there is a common column use argument 'on'\n# if two columns have the same values but different names use \"left_on\" and \"right_on\"\n# use argument how, if 'inner': merge on common data only in the common column, 'outer': merge all and non common will be none \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ORANGE3","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom Orange.data import table,domain\nfrom Orange.data.pandas_compat import table_from_frame\nfrom Orange.data.pandas_compat import table_to_frame \n#in_data, out_data\n#in_data.domain : columns of in_data\n#in_data.X  : X features of in_data\n#in_data.Y  :y target of in_data\n\n\ndf_1=table_to_frame(in_data)\nprint(df_1)\n#print(in_data.domain)\n#df=pd.DataFrame({'A':[1,2,3],'B':[3,3,3],'C':[4,4,4]})\nout_data = table_from_frame(df_1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom Orange.data import table,domain\nfrom Orange.data.pandas_compat import table_from_frame\nfrom Orange.data.pandas_compat import table_to_frame\nimport scipy.stats as stats\n#in_data, out_data\n#in_data.domain : columns of in_data\n#in_data.X  : X features of in_data\n#in_data.Y  :y target of in_data\ndf=table_to_frame(in_data)\ndef df_without_outliers (data,a=4):\n    '''\n    This function remove rows that contains any outliers larger than a value ( default a=4), a represents standard deviation\n    \n    - inputs : dataframe and a ( number of standard deviations)\n    - syntax : odf_without_outliers(df,a=4)\n    - output : columns that have the outliers > a* standard deviation of that column\n    '''\n    df=data.copy()    \n    z_scores = stats.zscore(df[df.describe().columns],nan_policy='omit')\n    z_scores.fillna(0,inplace=True)   # in case one column is filled with nan values\n    abs_z_scores = np.abs(z_scores)\n    filtered_entries = (abs_z_scores < a).all(axis=1)\n    df_without_outliers = df[filtered_entries]\n    return df_without_outliers\n\n#print(in_data.domain)\n#df=pd.DataFrame({'A':[1,2,3],'B':[3,3,3],'C':[4,4,4]})\nout_data = table_from_frame(df_without_outliers(df))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}